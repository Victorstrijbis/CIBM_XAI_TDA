import importlib
import os
import shutil

import h5py
import numpy as np
import torch
from torch import optim
import cv2

def save_checkpoint(state, is_best, checkpoint_dir, logger=None):
    """Saves model and training parameters at '{checkpoint_dir}/last_checkpoint.pytorch'.
    If is_best==True saves '{checkpoint_dir}/best_checkpoint.pytorch' as well.
    Args:
        state (dict): contains model's state_dict, optimizer's state_dict, epoch
            and best evaluation metric value so far
        is_best (bool): if True state contains the best model seen so far
        checkpoint_dir (string): directory where the checkpoint are to be saved
    """

    def log_info(message):
        if logger is not None:
            logger.info(message)

    if not os.path.exists(checkpoint_dir):
        log_info(
            f"Checkpoint directory does not exists. Creating {checkpoint_dir}")
        os.mkdir(checkpoint_dir)

    last_file_path = os.path.join(checkpoint_dir, 'last_checkpoint.pytorch')
    log_info(f"Saving last checkpoint to '{last_file_path}'")
    torch.save(state, last_file_path)
    if is_best:
        best_file_path = os.path.join(checkpoint_dir, 'best_checkpoint.pytorch')
        log_info(f"Saving best checkpoint to '{best_file_path}'")
        shutil.copyfile(last_file_path, best_file_path)


def load_checkpoint(checkpoint_path, model, optimizer=None,
                    model_key='model_state_dict', optimizer_key='optimizer_state_dict'):
    """Loads model and training parameters from a given checkpoint_path
    If optimizer is provided, loads optimizer's state_dict of as well.
    Args:
        checkpoint_path (string): path to the checkpoint to be loaded
        model (torch.nn.Module): model into which the parameters are to be copied
        optimizer (torch.optim.Optimizer) optional: optimizer instance into
            which the parameters are to be copied
    Returns:
        state
    """
    if not os.path.exists(checkpoint_path):
        raise IOError(f"Checkpoint '{checkpoint_path}' does not exist")

    state = torch.load(checkpoint_path, map_location='cpu')
    model.load_state_dict(state[model_key])

    if optimizer is not None:
        optimizer.load_state_dict(state[optimizer_key])

    return state


def save_network_output(output_path, output, logger=None):
    if logger is not None:
        logger.info(f'Saving network output to: {output_path}...')
    output = output.detach().cpu()[0]
    with h5py.File(output_path, 'w') as f:
        f.create_dataset('predictions', data=output, compression='gzip')





def get_number_of_learnable_parameters(model):
    model_parameters = filter(lambda p: p.requires_grad, model.parameters())
    return sum([np.prod(p.size()) for p in model_parameters])



def expand_as_one_hot(input, C, ignore_index=None):
    """
    Converts NxSPATIAL label image to NxCxSPATIAL, where each label gets converted to its corresponding one-hot vector.
    It is assumed that the batch dimension is present.
    Args:
        input (torch.Tensor): 3D/4D input image
        C (int): number of channels/labels
        ignore_index (int): ignore index to be kept during the expansion
    Returns:
        4D/5D output torch.Tensor (NxCxSPATIAL)
    """
    assert input.dim() == 4

    # expand the input tensor to Nx1xSPATIAL before scattering
    input = input.unsqueeze(1)
    # create output tensor shape (NxCxSPATIAL)
    shape = list(input.size())
    shape[1] = C

    if ignore_index is not None:
        # create ignore_index mask for the result
        mask = input.expand(shape) == ignore_index
        # clone the src tensor and zero out ignore_index in the input
        input = input.clone()
        input[input == ignore_index] = 0
        # scatter to get the one-hot tensor
        result = torch.zeros(shape).to(input.device).scatter_(1, input, 1)
        # bring back the ignore_index in the result
        result[mask] = ignore_index
        return result
    else:
        # scatter to get the one-hot tensor
        return torch.zeros(shape).to(input.device).scatter_(1, input, 1)


def convert_to_numpy(*inputs):
    """
    Coverts input tensors to numpy ndarrays
    Args:
        inputs (iteable of torch.Tensor): torch tensor
    Returns:
        tuple of ndarrays
    """

    def _to_numpy(i):
        assert isinstance(i, torch.Tensor), "Expected input to be torch.Tensor"
        return i.detach().cpu().numpy()

    return (_to_numpy(i) for i in inputs)


def create_optimizer(optimizer_config, model):
    learning_rate = optimizer_config['learning_rate']
    weight_decay = optimizer_config.get('weight_decay', 0)
    betas = tuple(optimizer_config.get('betas', (0.9, 0.999)))
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, weight_decay=weight_decay)
    return optimizer


def create_lr_scheduler(lr_config, optimizer):
    if lr_config is None:
        return None
    class_name = lr_config.pop('name')
    m = importlib.import_module('torch.optim.lr_scheduler')
    clazz = getattr(m, class_name)
    # add optimizer to the config
    lr_config['optimizer'] = optimizer
    return clazz(**lr_config)




def plot_heatmap(imgs, heatmaps):   
    superimposed_imgs = []
    for i in range(imgs.shape[2]):
        img = imgs[:, :, i]
        heatmap = heatmaps[:, :, i]
        
        heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGB2BGR)            
        
        img = np.uint8(255*img)
        
        superimposed_img = img.astype('int32')
        superimposed_img = np.stack([superimposed_img, superimposed_img, superimposed_img], axis=-1)
        superimposed_img[..., 0] = superimposed_img[..., 0] + 0.2*heatmap[..., 0]
        superimposed_img[..., 1] = superimposed_img[..., 1] + 0.1*heatmap[..., 1]
        superimposed_img[..., 2] = superimposed_img[..., 2] + 0.05*heatmap[..., 2]
        superimposed_img = np.uint8(255 * ((superimposed_img - np.min(superimposed_img)) 
                                        / (np.max(superimposed_img) - np.min(superimposed_img))))
        #superimposed_img = np.uint8(np.minimum(255, superimposed_img))
        superimposed_imgs.append(superimposed_img)
        
        
    superimposed_imgs = np.stack(superimposed_imgs, 2)
    
    return superimposed_imgs




def process_attributions(search_attributions, 
                         images,
                         use_pattern_change=False):
            
    if use_pattern_change:
        shift_x = np.zeros(search_attributions.shape)
        shift_y = np.zeros(search_attributions.shape)
        shift_z = np.zeros(search_attributions.shape)
        shift_x[:, :-1, :] = search_attributions[:, 1:, :]
        shift_y[:-1, :, :] = search_attributions[1:, :, :]
        shift_z[:, :, :-1] = search_attributions[:, :, 1:]
        shift_x[:, -1, :] = search_attributions[:, -2, :]
        shift_y[-1, :, :] = search_attributions[-2, :, :]
        shift_z[:, :, -1] = search_attributions[:, :, -2]
        search_attributions = abs(3 * search_attributions- shift_x - shift_y - shift_z)
        search_attributions = search_attributions ** 0.3
        
    
    attributions = plot_heatmap(images, search_attributions)  

    return attributions     
   
